{"cells":[{"cell_type":"markdown","source":["#Lab Machine Learning Hyper-parameter Tuning\n\nIn the practical machine learning works, itâ€™s very hard to find best parameters - such as learning rate (in neural networks), iterations or epoch,  kernel functions (in svm etc), [regularization parameters], so on and so forth. In Spark machine learning, you can quickly find best parameters by scaling Spark massive workers.\n\nIn this lab, we change the source code of Last exercise and find the best values of parameters - \"learningRate\" and \"numLeaves\" - for LightGBM classifier in last exercise by grid search. (Here we explore only classification's parameters, but you can also tune transformation's parameters.)\n\nBefore starting,\n\n- Install MMLSpark to use LightGBM into your cluster. (See Spark Machine Learning Pipeline\".)\n\n> Note : You can also use ```CrossValidator()``` instead of using ```TrainValidationSplit()```, but please be care for training overheads when using ```CrossValidator()```.    \nThe word \"Cross Validation\" means : For example, by setting ```numFolds=5``` in ```CrossValidator()```, 4/5 is used for training and 1/5 is for testing, and moreover each pairs are replaced and averaged. As a result, 5 pairs of dataset are used and the training occurs (3 params x 3 params) x 5 pairs = 45 times. \n\n(See \"[ML Tuning: model selection and hyperparameter tuning](https://spark.apache.org/docs/latest/ml-tuning.html)\" in official Spark document.)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"efc5011d-6bc8-4344-b1cd-d36206ab1ad3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Read dataset\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType\ndf = (sqlContext.read.format(\"csv\").\n  option(\"header\", \"true\").\n  option(\"nullValue\", \"NA\").\n  option(\"inferSchema\", True).\n  load(\"/FileStore/tables/flight_weather.csv\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b5cfbde5-0277-4642-9878-899b180789e5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# ARR_DEL15 = 1 if it's canceled.\nfrom pyspark.sql.functions import when\ndf = df.withColumn(\"ARR_DEL15\", when(df[\"CANCELLED\"] == 1, 1).otherwise(df[\"ARR_DEL15\"]))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3f469156-824e-4df0-969e-7c64863eb07f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Remove flights if it's diverted.\ndf = df.filter(df[\"DIVERTED\"] == 0)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"69a0d1c4-4fd6-4c94-aa1f-1e7fc4bfa766","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Select required columns\ndf = df.select(\n  \"ARR_DEL15\",\n  \"MONTH\",\n  \"DAY_OF_WEEK\",\n  \"UNIQUE_CARRIER\",\n  \"ORIGIN\",\n  \"DEST\",\n  \"CRS_DEP_TIME\",\n  \"CRS_ARR_TIME\",\n  \"RelativeHumidityOrigin\",\n  \"AltimeterOrigin\",\n  \"DryBulbCelsiusOrigin\",\n  \"WindSpeedOrigin\",\n  \"VisibilityOrigin\",\n  \"DewPointCelsiusOrigin\",\n  \"RelativeHumidityDest\",\n  \"AltimeterDest\",\n  \"DryBulbCelsiusDest\",\n  \"WindSpeedDest\",\n  \"VisibilityDest\",\n  \"DewPointCelsiusDest\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a27e8912-4dc8-45e6-8df4-e006b7add597","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Drop rows with null values\ndf = df.dropna()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dc6164bc-fb6c-4594-8918-dd4c782c7701","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Convert categorical values to indexer (0, 1, ...)\nfrom pyspark.ml.feature import StringIndexer\nuniqueCarrierIndexer = StringIndexer(inputCol=\"UNIQUE_CARRIER\", outputCol=\"Indexed_UNIQUE_CARRIER\").fit(df)\noriginIndexer = StringIndexer(inputCol=\"ORIGIN\", outputCol=\"Indexed_ORIGIN\").fit(df)\ndestIndexer = StringIndexer(inputCol=\"DEST\", outputCol=\"Indexed_DEST\").fit(df)\narrDel15Indexer = StringIndexer(inputCol=\"ARR_DEL15\", outputCol=\"Indexed_ARR_DEL15\").fit(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f3e85f54-ba7f-4456-848f-fb1144cca30d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Assemble feature columns\nfrom pyspark.ml.feature import VectorAssembler\nassembler = VectorAssembler(\n  inputCols = [\n    \"MONTH\",\n    \"DAY_OF_WEEK\",\n    \"Indexed_UNIQUE_CARRIER\",\n    \"Indexed_ORIGIN\",\n    \"Indexed_DEST\",\n    \"CRS_DEP_TIME\",\n    \"CRS_ARR_TIME\",\n    \"RelativeHumidityOrigin\",\n    \"AltimeterOrigin\",\n    \"DryBulbCelsiusOrigin\",\n    \"WindSpeedOrigin\",\n    \"VisibilityOrigin\",\n    \"DewPointCelsiusOrigin\",\n    \"RelativeHumidityDest\",\n    \"AltimeterDest\",\n    \"DryBulbCelsiusDest\",\n    \"WindSpeedDest\",\n    \"VisibilityDest\",\n    \"DewPointCelsiusDest\"],\n  outputCol = \"features\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a175e949-cb3d-4d7d-837c-d8e99383d99f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Define classifier\nfrom synapse.ml.lightgbm import LightGBMClassifier\n#from mmlspark.lightgbm import LightGBMClassifier\nclassifier = LightGBMClassifier(featuresCol=\"features\", labelCol=\"ARR_DEL15\", numIterations=10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bf06fb5b-58ec-472e-9fd2-097d4c801a83","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Create pipeline\nfrom pyspark.ml import Pipeline\npipeline = Pipeline(stages=[uniqueCarrierIndexer, originIndexer, destIndexer, arrDel15Indexer, assembler, classifier])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f13a498c-98d4-4a96-8515-5e2f0513aa01","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Note : The following execution will take a long time, because of a serial evaluation by default.    \nUse ```setParallelism()``` to improve performance."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f0f23c6e-27d6-41c6-9592-daf055803fe7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# We use a ParamGridBuilder to construct a grid of parameters to search over.\n# Run pipeline with ParamGridBuilder\nfrom pyspark.ml.tuning import ParamGridBuilder\nfrom pyspark.ml.tuning import TrainValidationSplit\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n# 3 x 3 = 9 times training occurs\n\n # learning rate=0.1, (100, 150, 200, 250, 300), accuracy= (0.78, ?, ?, ?, ?, ?) \n# learning rate= 0.3, (100, 150, 200, 250, 300),  accuracy= (0.78, ?, ?, ?, ?, ?) \n# learning rate=0.5, (100, 150, 200, 250, 300),  accuracy= (0.78, ?, ?, ?, ?, ?) \n# learning rate=0.6, (100, 150, 200, 250, 300),  accuracy= (0.78, ?, ?, ?, ?, ?) \n\n\n\n# num leaves=100, learning [0.1, 0.3. 0.5, 0.6] time =[?, ?, ?, ?]/ walltime\n# num leaves=150, learning [0.1, 0.3. 0.5, 0.6] time =[?, ?, ?, ?] walltime\n# num leaves=200, learning [0.1, 0.3. 0.5, 0.6] time =[?, ?, ?, ?] walltime\n# num leaves=250, learning [0.1, 0.3. 0.5, 0.6] time =[?, ?, ?, ?] walltime\n# num leaves=3100, learning [0.1, 0.3. 0.5, 0.6] time =[?, ?, ?, ?] walltime\n\n# learning=0.1, [100, 150, 200, 250,300], time =[?, ?, ?, ?,?,?] walltime\n# learning=0.6, [100, 150, 200, 250,300], time =[?, ?, ?, ?,?,?]walltime\n# learning=0.2, [100, 150, 200, 250,300], time =[?, ?, ?, ?,?,?] walltime\n\nparamGrid = ParamGridBuilder() \\\n .addGrid(classifier.learningRate, [0.1, 0.3, 0.5, 0.6]) \\\n .addGrid(classifier.numLeaves, [100, 150, 200, 250,300]) \\\n .build()\n\n#   TrainValidationSplit creates a single (training, test) dataset pair. It splits the dataset into these two parts using the trainRatio parameter. For example with trainRatio=0.75, TrainValidationSplit will generate a training and test dataset pair where 75% of the data is used for training and 25% for validation. A must reading from https://spark.apache.org/docs/2.0.2/ml-tuning.html\n## https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator.metricName\n## This is an instance of an Evaluator. It allows to compute the some common measure for classification tasks. It computes precision, recall, f1s for each class, and a global accuracy.\n\n# Set appropriate parallelism by setParallelism() in production\n# (It takes a long time)\ntvs = TrainValidationSplit(\n  estimator=pipeline,\n  estimatorParamMaps=paramGrid,\n  evaluator=MulticlassClassificationEvaluator(labelCol=\"ARR_DEL15\", predictionCol=\"prediction\"),\n  trainRatio=0.8)  # data is separated by 80% and 20%, in which the former is used for training and the later for evaluation\nmodel = tvs.fit(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aa89d90c-bd23-49aa-852e-a8fee06cf1c4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# The hyperparameters as well as the evaluations are exposed by getEstimatorParamMaps and validationMetrics, respectively. They can be combined to display all of the parameter combinations sorted by metric value\n# View all results (accuracy) by each params. Read further from here https://www.oreilly.com/library/view/advanced-analytics-with/9781491972946/ch04.html\nlist(zip(model.validationMetrics, model.getEstimatorParamMaps()))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"61d3743a-0390-49aa-ad1c-dbe91e9788a4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[21]: [(0.7322311897943244,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.1,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 100}),\n (0.7322311897943244,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.1,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 150}),\n (0.7322311897943244,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.1,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 200}),\n (0.7322311897943244,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.1,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 250}),\n (0.7322311897943244,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.1,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 300}),\n (0.7390044056929648,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.3,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 100}),\n (0.7390044056929648,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.3,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 150}),\n (0.7390044056929648,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.3,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 200}),\n (0.7390044056929648,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.3,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 250}),\n (0.7390044056929648,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.3,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 300}),\n (0.7735092982440973,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.5,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 100}),\n (0.7735092982440973,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.5,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 150}),\n (0.7735092982440973,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.5,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 200}),\n (0.7735092982440973,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.5,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 250}),\n (0.7735092982440973,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.5,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 300}),\n (0.7414232512226859,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.6,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 100}),\n (0.7414232512226859,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.6,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 150}),\n (0.7414232512226859,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.6,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 200}),\n (0.7414232512226859,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.6,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 250}),\n (0.7414232512226859,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.6,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 300})]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[21]: [(0.7322311897943244,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.1,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 100}),\n (0.7322311897943244,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.1,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 150}),\n (0.7322311897943244,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.1,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 200}),\n (0.7322311897943244,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.1,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 250}),\n (0.7322311897943244,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.1,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 300}),\n (0.7390044056929648,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.3,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 100}),\n (0.7390044056929648,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.3,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 150}),\n (0.7390044056929648,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.3,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 200}),\n (0.7390044056929648,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.3,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 250}),\n (0.7390044056929648,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.3,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 300}),\n (0.7735092982440973,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.5,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 100}),\n (0.7735092982440973,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.5,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 150}),\n (0.7735092982440973,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.5,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 200}),\n (0.7735092982440973,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.5,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 250}),\n (0.7735092982440973,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.5,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 300}),\n (0.7414232512226859,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.6,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 100}),\n (0.7414232512226859,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.6,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 150}),\n (0.7414232512226859,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.6,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 200}),\n (0.7414232512226859,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.6,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 250}),\n (0.7414232512226859,\n  {Param(parent='LightGBMClassifier_1c1039c3337d', name='learningRate', doc='Learning rate or shrinkage rate'): 0.6,\n   Param(parent='LightGBMClassifier_1c1039c3337d', name='numLeaves', doc='Number of leaves'): 300})]"]}}],"execution_count":0},{"cell_type":"code","source":["#method transform(), which converts one DataFrame into another, generally by appending one or more columns.\n# Predict using best model\n# Use the transform method on the trained model to see its prediction. Now that lrModel is a trained estimator, we can transform data using its .transform() method.v\ndf10 = df.limit(10)\nmodel.bestModel.transform(df10)\\\n  .select(\"ARR_DEL15\", \"prediction\")\\\n  .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0f7b8de4-db14-43ec-a47e-7d72267f7955","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+----------+\n|ARR_DEL15|prediction|\n+---------+----------+\n|        0|       0.0|\n|        0|       0.0|\n|        0|       0.0|\n|        1|       1.0|\n|        0|       0.0|\n|        0|       0.0|\n|        0|       0.0|\n|        0|       0.0|\n|        1|       1.0|\n|        0|       0.0|\n+---------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+----------+\n|ARR_DEL15|prediction|\n+---------+----------+\n|        0|       0.0|\n|        0|       0.0|\n|        0|       0.0|\n|        1|       1.0|\n|        0|       0.0|\n|        0|       0.0|\n|        0|       0.0|\n|        0|       0.0|\n|        1|       1.0|\n|        0|       0.0|\n+---------+----------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ML-hyperparams-tuning_BB_Databricks","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":793024554601717}},"nbformat":4,"nbformat_minor":0}
